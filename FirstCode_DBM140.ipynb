{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code is coppied and adapted from the following webpage:\n",
    "# https://www.geeksforgeeks.org/emotion-detection-using-bidirectional-lstm/\n",
    "\n",
    "\n",
    "#Make sure your file address for this code contains \"glove.6B.50d.txt\"\n",
    "#If not, get it with Google Drive or https://nlp.stanford.edu/projects/glove/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\20193043\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the required libraries\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Bidirectional\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from keras.layers import *\n",
    "from sklearn.model_selection import cross_val_score \n",
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous code for import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from py_isear.isear_loader import IsearLoader\n",
    "attributes = ['EMOT','SIT']\n",
    "target = ['TROPHO','TEMPER']\n",
    "loader = IsearLoader(attributes, target, True)\n",
    "data = loader.load_isear('isear.csv')\n",
    "\n",
    "data.drop(data[data[1] == '[ No response.]'].index, inplace = True)\n",
    "print(data.head())\n",
    "#Hide it for now or the github page always takes forever to browse ;)\n",
    "#data.get_data() # returns attributes\n",
    "#data.get_target() # returns target\n",
    "#data.get_freetext_content() # returns the text content of the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMOTION</th>\n",
       "      <th>SIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>During the period of falling in love, each tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>When I was involved in a traffic accident.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I was driving home after  several days of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I lost the person who meant the most to me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>The time I knocked a deer down - the sight of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7421</th>\n",
       "      <td>anger</td>\n",
       "      <td>Two years back someone invited me to be the tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7422</th>\n",
       "      <td>sadness</td>\n",
       "      <td>I had taken the responsibility to do something...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7423</th>\n",
       "      <td>disgust</td>\n",
       "      <td>I was at home and I heard a loud sound of spit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7424</th>\n",
       "      <td>shame</td>\n",
       "      <td>I did not do the homework that the teacher had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7425</th>\n",
       "      <td>guilt</td>\n",
       "      <td>I had shouted at my younger brother and he was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7426 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      EMOTION                                                SIT\n",
       "0         joy  During the period of falling in love, each tim...\n",
       "1        fear         When I was involved in a traffic accident.\n",
       "2       anger  When I was driving home after  several days of...\n",
       "3     sadness  When I lost the person who meant the most to me. \n",
       "4     disgust  The time I knocked a deer down - the sight of ...\n",
       "...       ...                                                ...\n",
       "7421    anger  Two years back someone invited me to be the tu...\n",
       "7422  sadness  I had taken the responsibility to do something...\n",
       "7423  disgust  I was at home and I heard a loud sound of spit...\n",
       "7424    shame  I did not do the homework that the teacher had...\n",
       "7425    guilt  I had shouted at my younger brother and he was...\n",
       "\n",
       "[7426 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset_edits/text_emotion_isear_edit2.csv', header=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMOTION</th>\n",
       "      <th>SIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>During the period of falling in love, each tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>When I was involved in a traffic accident.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I was driving home after  several days of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I lost the person who meant the most to me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>The time I knocked a deer down - the sight of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7421</th>\n",
       "      <td>anger</td>\n",
       "      <td>Two years back someone invited me to be the tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7422</th>\n",
       "      <td>sadness</td>\n",
       "      <td>I had taken the responsibility to do something...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7423</th>\n",
       "      <td>disgust</td>\n",
       "      <td>I was at home and I heard a loud sound of spit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7424</th>\n",
       "      <td>shame</td>\n",
       "      <td>I did not do the homework that the teacher had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7425</th>\n",
       "      <td>guilt</td>\n",
       "      <td>I had shouted at my younger brother and he was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7426 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      EMOTION                                                SIT\n",
       "0         joy  During the period of falling in love, each tim...\n",
       "1        fear         When I was involved in a traffic accident.\n",
       "2       anger  When I was driving home after  several days of...\n",
       "3     sadness  When I lost the person who meant the most to me. \n",
       "4     disgust  The time I knocked a deer down - the sight of ...\n",
       "...       ...                                                ...\n",
       "7421    anger  Two years back someone invited me to be the tu...\n",
       "7422  sadness  I had taken the responsibility to do something...\n",
       "7423  disgust  I was at home and I heard a loud sound of spit...\n",
       "7424    shame  I did not do the homework that the teacher had...\n",
       "7425    guilt  I had shouted at my younger brother and he was...\n",
       "\n",
       "[7426 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Changed a bit as now we have a DataFrame\n",
    "df.drop(df[df['SIT'] == '[ No response.]'].index, inplace = True)\n",
    "df\n",
    "#this does not work since the structure of the ISEAR file on the website is very different than the one we use, the one we use has a lot of additional data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION\n",
      "fear       1074\n",
      "sadness    1068\n",
      "anger      1062\n",
      "joy        1061\n",
      "shame      1060\n",
      "guilt      1056\n",
      "disgust    1045\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Take a look of the numbers of each emotion\n",
    "print (df['EMOTION'].value_counts() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTION\n",
      "fear       1074\n",
      "sadness    1068\n",
      "joy        1061\n",
      "shame      1060\n",
      "guilt      1056\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#let's get rid of anger and disgust to have a try\n",
    "df = df[~df['EMOTION'].isin(['anger', 'disgust'])]\n",
    "print (df['EMOTION'].value_counts() )\n",
    "\n",
    "number_emotions = df['EMOTION'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#HIGHTLIGHT#HIGHTLIGHT#HIGHTLIGHT#HIGHTLIGHT#HIGHTLIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       During the period of falling in love, each tim...\n",
      "1              When I was involved in a traffic accident.\n",
      "3       When I lost the person who meant the most to me. \n",
      "5                         When I did not speak the truth.\n",
      "6       When I caused problems for somebody because he...\n",
      "                              ...                        \n",
      "7419           I received a letter from a distant friend.\n",
      "7420    My parents were out and I was the eldest at ho...\n",
      "7422    I had taken the responsibility to do something...\n",
      "7424    I did not do the homework that the teacher had...\n",
      "7425    I had shouted at my younger brother and he was...\n",
      "Name: SIT, Length: 5319, dtype: object\n",
      "when i lost the person who meant the most to me. \n",
      "0       during the period of falling in love, each tim...\n",
      "1              when i was involved in a traffic accident.\n",
      "3       when i lost the person who meant the most to me. \n",
      "5                         when i did not speak the truth.\n",
      "6       when i caused problems for somebody because he...\n",
      "                              ...                        \n",
      "7419           i received a letter from a distant friend.\n",
      "7420    my parents were out and i was the eldest at ho...\n",
      "7422    i had taken the responsibility to do something...\n",
      "7424    i did not do the homework that the teacher had...\n",
      "7425    i had shouted at my younger brother and he was...\n",
      "Name: SIT, Length: 5319, dtype: object\n",
      "['this', 'is', 'an', 'event', 'i', 'will', 'never', 'forget', '.', 'i', 'am', 'considered', 'a', 'good', 'ã¡', 'mimic', '.', 'this', 'particular', 'day', 'we', 'were', 'waiting', 'for', 'a', 'professor', 'ã¡', 'to', 'take', 'her', 'class', '.', 'this', 'professor', 'had', 'a', 'peculiar', 'accent', 'and', 'a', 'ã¡', 'very', 'horrible', 'way', 'of', 'lecturing', 'and', 'to', 'top', 'it', 'all', 'we', 'had', 'this', 'ã¡', 'class', 'at', 'the', 'fag', 'end', 'of', 'the', 'day', '.', 'so', 'this', 'particular', 'day', 'i', 'got', 'ã¡', 'into', 'my', 'element', 'and', 'started', 'imitating', 'the', 'professor', ',', 'and', 'the', 'ã¡', 'professor', 'entered', 'the', 'class', 'right', 'in', 'the', 'middle', 'of', 'it', '.', 'i', 'was', 'ã¡', 'unaware', 'of', 'her', 'presence', ',', 'some', 'of', 'my', 'friends', 'tried', 'to', 'warn', 'me', 'but', 'ã¡', 'it', 'was', 'of', 'no', 'avail', 'as', 'i', 'was', 'too', 'engrossed', 'in', 'mimicing', '.', 'then', 'i', 'ã¡', 'suddenly', 'noticed', 'the', 'silence', 'and', 'turned', 'around', 'to', 'see', 'her', 'ã¡', 'entering', 'the', 'class', '.', 'i', 'do', 'not', 'know', 'till', 'today', 'if', 'she', 'actually', 'saw', 'ã¡', 'what', 'i', 'had', 'been', 'doing', 'or', 'she', 'had', 'completely', 'ignored', 'it', '.', 'through', 'ã¡', 'out', 'that', 'lecture', 'i', 'died', 'of', 'shame', '.', 'all', 'the', 'more', 'shameful', 'was', 'the', 'ã¡', 'fact', 'that', 'she', 'gave', 'me', 'a', 'character', 'certificate', '.']\n",
      "Sublist with the most elements: 192\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#make all contexts (sentences) in dataset a list\n",
    "texts =df[\"SIT\"]\n",
    "print(texts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#HIGHTLIGHT\n",
    "#Convert each text value to lowercase using the .str.lower() method\n",
    "lower_texts = texts.str.lower()\n",
    "\n",
    "print (lower_texts[3])\n",
    "\n",
    "\n",
    "print(lower_texts)\n",
    "# Each  sentence in feel_arr is tokenized by the help of work tokenizer.\n",
    "# If I have a sentence - 'I am happy'. \n",
    "# After word tokenizing it will convert into- ['I','am','happy']\n",
    "lower_texts = [word_tokenize(sent) for sent in lower_texts]\n",
    "\n",
    "\n",
    "#Now I added some codes to see how many words it has for the longest text\n",
    "longest_text = max(lower_texts, key=len)\n",
    "print (longest_text)\n",
    "print(\"Sublist with the most elements:\", len(longest_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somehow we don't have the same dataset as our longest text has 200 words. <br>\n",
    "for the next part I two choices: <br>\n",
    "1. change the length for all sentences into 200, then it takes more time to train the model <br>\n",
    "2. drop all texts more than certain words, 100 for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to try the first way to see if its doable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['during', 'the', 'period', 'of', 'falling', 'in', 'love', ',', 'each', 'time', 'that', 'we', 'met', 'and', 'ã¡', 'especially', 'when', 'we', 'had', 'not', 'met', 'for', 'a', 'long', 'time', '.', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Defined a function padd in which each sentence length is fixed to 200.\n",
    "# If length is less than 200 , then the word- '<padd>' is append\n",
    "def padd(arr):\n",
    "    for i in range(200-len(arr)):\n",
    "        arr.append('<pad>')\n",
    "    return arr[:200]\n",
    "   \n",
    "# call the padd function for each sentence in feel_arr\n",
    "for i in range(len(lower_texts)):\n",
    "    lower_texts[i]=padd(lower_texts[i])\n",
    " \n",
    "\n",
    "\n",
    "print(lower_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.013441,  0.23682 , -0.16899 ,  0.40951 ,  0.63812 ,  0.47709 ,\n",
       "       -0.42852 , -0.55641 , -0.364   , -0.23938 ,  0.13001 , -0.063734,\n",
       "       -0.39575 , -0.48162 ,  0.23291 ,  0.090201, -0.13324 ,  0.078639,\n",
       "       -0.41634 , -0.15428 ,  0.10068 ,  0.48891 ,  0.31226 , -0.1252  ,\n",
       "       -0.037512, -1.5179  ,  0.12612 , -0.02442 , -0.042961, -0.28351 ,\n",
       "        3.5416  , -0.11956 , -0.014533, -0.1499  ,  0.21864 , -0.33412 ,\n",
       "       -0.13872 ,  0.31806 ,  0.70358 ,  0.44858 , -0.080262,  0.63003 ,\n",
       "        0.32111 , -0.46765 ,  0.22786 ,  0.36034 , -0.37818 , -0.56657 ,\n",
       "        0.044691,  0.30392 ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Glove vector contains a 50 dimensional vector corresponding \n",
    "# to each word in dictionary.\n",
    "vocab_f = 'glove.6B.50d.txt'\n",
    " \n",
    "# embeddings_index is a dictionary which contains the mapping of\n",
    "# word with its corresponding 50d vector.\n",
    "embeddings_index = {}\n",
    "with open(vocab_f, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        # splitting each line of the glove.6B.50d in a list of \n",
    "        # items- in which the first element is the word to be embedded,\n",
    "        # and from second to the end of line contains the 50d vector.\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "         \n",
    "# the embedding index of ','\n",
    "embeddings_index[',']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.29784   -0.018422  -0.71891   -0.4651    -0.45661   -0.0042153\n",
      " -0.74598    0.34662   -0.51781   -0.5877     0.18398   -0.36903\n",
      " -0.52225   -0.14082    0.83446   -0.26962   -0.89364   -0.11813\n",
      " -1.3076     0.475      0.52815   -0.021974   0.61869   -0.65362\n",
      " -0.14298   -1.6466    -0.05305   -0.17046    0.17048    0.75756\n",
      "  3.5832     0.13775   -0.37811   -0.48736    0.0069906  0.59913\n",
      "  0.31404    0.30734   -0.42397    0.35383   -0.97151    0.16082\n",
      " -0.63666   -0.20449   -0.070846  -0.32219   -0.049254  -0.41865\n",
      " -0.6899    -0.54908  ]\n"
     ]
    }
   ],
   "source": [
    "# Embedding each word of the feel_arr\n",
    "embedding_texts = []\n",
    "# Iterate through each sub-list (sentences)\n",
    "for word_list in lower_texts:\n",
    "    # Initialize an empty list to store the embedding vectors for each word\n",
    "    word_vectors = []\n",
    "    for word in word_list:\n",
    "        if word in embeddings_index:\n",
    "            word_vector = embeddings_index[word]\n",
    "            word_vectors.append(word_vector)\n",
    "        else:\n",
    "            # if the word to be embedded is '<padd>' append 0 fifty times\n",
    "            word_vector = np.zeros(50, dtype='float32')\n",
    "            word_vectors.append(word_vector)\n",
    "    embedding_texts.append(word_vectors)\n",
    "\n",
    "print(embedding_texts[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!!PROBLEM!!!!!<br>\n",
    "I checked and found the the GloVe cannot recognize the capital letters. <br>\n",
    "I can transfer all the capital letters into lowercase but the problem is for text message I personally uer capital letters a lot for emotion presentation<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data should be ready (FINALLY) for training <br>\n",
    "but still we need to coupling those random numbers with emotion (Input) <br>\n",
    "Also we need to divide the data into training and testing sets. <br>\n",
    "There are plenty of ways to divide, but to make it simple, I'll just make it 8:2 randomized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the Input, we can add more if we have more time.<br>\n",
    "For instance, the length of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print (type(embedding_texts))\n",
    "\n",
    "#embeeding_texts cannot be a list, for the website he made it NumPy-array\n",
    "X = np.array(embedding_texts)\n",
    "print (type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_fear</th>\n",
       "      <th>emotion_guilt</th>\n",
       "      <th>emotion_joy</th>\n",
       "      <th>emotion_sadness</th>\n",
       "      <th>emotion_shame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7419</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7420</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7422</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7424</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7425</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5319 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emotion_fear  emotion_guilt  emotion_joy  emotion_sadness  emotion_shame\n",
       "0            False          False         True            False          False\n",
       "1             True          False        False            False          False\n",
       "3            False          False        False             True          False\n",
       "5            False          False        False            False           True\n",
       "6            False           True        False            False          False\n",
       "...            ...            ...          ...              ...            ...\n",
       "7419         False          False         True            False          False\n",
       "7420          True          False        False            False          False\n",
       "7422         False          False        False             True          False\n",
       "7424         False          False        False            False           True\n",
       "7425         False           True        False            False          False\n",
       "\n",
       "[5319 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One-Hot Encoding for all emotions, \n",
    "#instead of just give them numbers, by doing so we will have five outputs\n",
    "\n",
    "Y = pd.get_dummies(df['EMOTION'], prefix='emotion')\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split into train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I didn't check the distributions of emotions at the beginning. Now it just use the simpliest way to divide the dataset. <br>\n",
    "If we get more time we should take a bit more time to analyize the datasets to choose a better way to divide. <br>\n",
    "e.g. there are 40% of texts are all joy while only 5% of them are guilty <br>\n",
    "Then the simple randomized distribution will make a horrible model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now everything is ready to go and we can design the layers for the model <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMModel:\n",
    "    def __init__(self):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Input(shape=(200, 50)))\n",
    "        \n",
    "        self.model.add(Bidirectional(LSTM(64, input_shape=(200, 50))))\n",
    "\n",
    "        self.model.add(Dropout(0.2))\n",
    "        \n",
    "        self.model.add(Dense(5, activation='softmax'))\n",
    "        self.model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    " \n",
    "    def fit(self, X, Y, epochs, batch_size,verbose):\n",
    "        self.model.fit(X, Y, epochs=epochs, batch_size=batch_size,verbose=verbose)\n",
    " \n",
    "    def evaluate(self, X, Y, batch_size,verbose):\n",
    "        return self.model.evaluate(X, Y, batch_size=batch_size,verbose=verbose)\n",
    " \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirection  (None, 128)               58880     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59525 (232.52 KB)\n",
      "Trainable params: 59525 (232.52 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTMModel()\n",
    "# Take a look of the model layers summarry\n",
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I (Sikai) said on Tuesday (10/17/2023) was incorrect that as we were using sequential to build the model, it never shows the input lay. <br>\n",
    "So the BiLSTM layer is already the hiddent layer (so second layer) <br>\n",
    "Our model in fact has layers as below: <br>\n",
    "Input layer <None,200,50>   ------->   BiLSTM layer <None,128>  -----------> Dropout 20% of them randomly --------------> Dense layer (fully connected) <None,5> <br>\n",
    "\n",
    "For the input layer<br>\n",
    "200 is the length of a sentence (the longest sentence is 200 words), 50 is the number of dimentions of each word (depends on GloVe we used) <br>\n",
    "\n",
    "For the BiLSTM layer<br>\n",
    "128 is number of nodes, it can be set by us. what we did before (200) is in fact not neccesary and a bit misleading. It is based on the input (200 words) but the output is not word by word. The output is in fact a new concept (not sure if it's correct). Max please help me explain this if you can ;) <br>\n",
    "\n",
    "For Dropout Layer <br>\n",
    "Each time it drop 20%(we can change this value as we want) of nodes from the BiLSTM layer to avoid overfitting<br>\n",
    "\n",
    "For Dense layer <br>\n",
    "The output layer, dense means each input has to be connected to the five nodes of it (five emotions we have). So each input will contributed to the five emotion prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "266/266 [==============================] - 11s 33ms/step - loss: 1.4648 - accuracy: 0.3732\n",
      "Epoch 2/7\n",
      "266/266 [==============================] - 9s 33ms/step - loss: 1.2761 - accuracy: 0.4801\n",
      "Epoch 3/7\n",
      "266/266 [==============================] - 9s 34ms/step - loss: 1.1774 - accuracy: 0.5246\n",
      "Epoch 4/7\n",
      "266/266 [==============================] - 9s 35ms/step - loss: 1.1118 - accuracy: 0.5544\n",
      "Epoch 5/7\n",
      "266/266 [==============================] - 9s 35ms/step - loss: 1.0644 - accuracy: 0.5772\n",
      "Epoch 6/7\n",
      "266/266 [==============================] - 10s 39ms/step - loss: 1.0094 - accuracy: 0.6049\n",
      "Epoch 7/7\n",
      "266/266 [==============================] - 11s 40ms/step - loss: 0.9669 - accuracy: 0.6277\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# create an instance of the BiLSTMModel class\n",
    "model = BiLSTMModel()\n",
    "\n",
    "\n",
    "# fit the model on the input and target data\n",
    "model.fit(X_train,Y_train, epochs=7, batch_size=16,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0809788703918457\n",
      "Accuracy: 0.5911654233932495\n"
     ]
    }
   ],
   "source": [
    "#now we can check the performance of the model with the testing sets\n",
    "loss,accuracy = model.evaluate(X_test, Y_test, 16,verbose = 0)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code to test the best epochs, it will <br>\n",
    "1. train the model for one epoch <br>\n",
    "2. evaluation the test data with the testing model that it will get the accuracy and loss for testing dataset <br>\n",
    "3. print the accuracy for both train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compar(self, X_train, Y_train, X_test, Y_test, epochs, batch_size):\n",
    "    train_accuracy_history = []  # For recording train accuracy\n",
    "    test_accuracy_history = []   # For recording test accuracy\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        history = self.model.fit(X_train, Y_train, epochs=1, batch_size=batch_size, verbose=0)\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        train_accuracy = history.history['accuracy'][0]\n",
    "        train_accuracy_history.append(train_accuracy)\n",
    "\n",
    "\n",
    "        test_loss, test_accuracy = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=0)\n",
    "        test_accuracy_history.append(test_accuracy)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs}' )\n",
    "        print(f'Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "    return train_accuracy_history, test_accuracy_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "always reset the model with \"model = BiLSTMModel()'<br>\n",
    "or we are just trainning more cycle (epoch) from the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Train Accuracy: 0.3558, Test Accuracy: 0.4690\n",
      "Epoch 2/15\n",
      "Train Accuracy: 0.4651, Test Accuracy: 0.5273\n",
      "Epoch 3/15\n",
      "Train Accuracy: 0.5119, Test Accuracy: 0.4812\n",
      "Epoch 4/15\n",
      "Train Accuracy: 0.5481, Test Accuracy: 0.5442\n",
      "Epoch 5/15\n",
      "Train Accuracy: 0.5788, Test Accuracy: 0.5301\n",
      "Epoch 6/15\n",
      "Train Accuracy: 0.6127, Test Accuracy: 0.5789\n",
      "Epoch 7/15\n",
      "Train Accuracy: 0.6329, Test Accuracy: 0.5780\n",
      "Epoch 8/15\n",
      "Train Accuracy: 0.6508, Test Accuracy: 0.6156\n",
      "Epoch 9/15\n",
      "Train Accuracy: 0.6625, Test Accuracy: 0.6156\n",
      "Epoch 10/15\n",
      "Train Accuracy: 0.6830, Test Accuracy: 0.6081\n",
      "Epoch 11/15\n",
      "Train Accuracy: 0.7034, Test Accuracy: 0.6081\n",
      "Epoch 12/15\n",
      "Train Accuracy: 0.7126, Test Accuracy: 0.6250\n",
      "Epoch 13/15\n",
      "Train Accuracy: 0.7288, Test Accuracy: 0.6269\n",
      "Epoch 14/15\n",
      "Train Accuracy: 0.7434, Test Accuracy: 0.6316\n",
      "Epoch 15/15\n",
      "Train Accuracy: 0.7544, Test Accuracy: 0.6316\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTMModel()\n",
    "\n",
    "\n",
    "epochs=15\n",
    "batch_size = 16\n",
    "train_accuracy_history, test_accuracy_history = compar(model,X_train, Y_train, X_test, Y_test, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code to save the accuracies tested above <br>\n",
    "It will be saved a cvs file named: \"accuracy_apochs_XX_batch_XX.cvs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it a DataFrame\n",
    "merged_train_accuracy_history = df = pd.DataFrame({\n",
    "    'train_accuracy_history': train_accuracy_history,\n",
    "    'test_accuracy_history': test_accuracy_history\n",
    "})\n",
    "\n",
    "\n",
    "# Export data to CSV file\n",
    "file_name = f\"64accuracy_epochs_{epochs}_batch_{batch_size}.csv\"\n",
    "df.to_csv(file_name, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the result above, we can choose the ideal number of epochs to trian the model and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "266/266 [==============================] - 13s 39ms/step - loss: 1.4668 - accuracy: 0.3725\n",
      "Epoch 2/13\n",
      "266/266 [==============================] - 10s 39ms/step - loss: 1.2823 - accuracy: 0.4780\n",
      "Epoch 3/13\n",
      "266/266 [==============================] - 10s 38ms/step - loss: 1.2077 - accuracy: 0.5100\n",
      "Epoch 4/13\n",
      "266/266 [==============================] - 10s 39ms/step - loss: 1.1226 - accuracy: 0.5565\n",
      "Epoch 5/13\n",
      "266/266 [==============================] - 10s 39ms/step - loss: 1.0616 - accuracy: 0.5899\n",
      "Epoch 6/13\n",
      "266/266 [==============================] - 10s 38ms/step - loss: 1.0008 - accuracy: 0.6061\n",
      "Epoch 7/13\n",
      "266/266 [==============================] - 10s 39ms/step - loss: 0.9466 - accuracy: 0.6329\n",
      "Epoch 8/13\n",
      "266/266 [==============================] - 10s 39ms/step - loss: 0.9032 - accuracy: 0.6571\n",
      "Epoch 9/13\n",
      "266/266 [==============================] - 10s 39ms/step - loss: 0.8631 - accuracy: 0.6613\n",
      "Epoch 10/13\n",
      "266/266 [==============================] - 10s 39ms/step - loss: 0.8268 - accuracy: 0.6848\n",
      "Epoch 11/13\n",
      "266/266 [==============================] - 10s 39ms/step - loss: 0.7939 - accuracy: 0.6940\n",
      "Epoch 12/13\n",
      "266/266 [==============================] - 10s 39ms/step - loss: 0.7488 - accuracy: 0.7135\n",
      "Epoch 13/13\n",
      "266/266 [==============================] - 11s 40ms/step - loss: 0.7231 - accuracy: 0.7217\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTMModel()\n",
    "model.fit(X_train,Y_train, epochs=13, batch_size=16,verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.095611810684204\n",
      "Accuracy: 0.5845864415168762\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test, Y_test, 16,verbose = 0)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just addedd some code to save the model \n",
    "\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "CHANGE THE NAME YOU SAVE YOUR MODEL TO\n",
    "\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BiLSTMModel' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\4K\\Documents\\GitHub\\DBM140\\FirstCode_DBM140.ipynb Cell 43\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/4K/Documents/GitHub/DBM140/FirstCode_DBM140.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Uncomment this piece of code if you want to save the model \u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/4K/Documents/GitHub/DBM140/FirstCode_DBM140.ipynb#X60sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49msave(\u001b[39m'\u001b[39m\u001b[39mtrained_model_Sikai_20231020_1.h5\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# creates a HDF5 file 'my_model.h5'\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/4K/Documents/GitHub/DBM140/FirstCode_DBM140.ipynb#X60sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#del model  # deletes the existing model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/4K/Documents/GitHub/DBM140/FirstCode_DBM140.ipynb#X60sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/4K/Documents/GitHub/DBM140/FirstCode_DBM140.ipynb#X60sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#returns a compiled model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/4K/Documents/GitHub/DBM140/FirstCode_DBM140.ipynb#X60sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#identical to the previous one\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/4K/Documents/GitHub/DBM140/FirstCode_DBM140.ipynb#X60sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m#model = load_model('')\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BiLSTMModel' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "#Uncomment this piece of code if you want to save the model \n",
    "\n",
    "model.save('models/trained_model_Sikai_20231020_1.keras')  # creates a HDF5 file 'my_model.h5'\n",
    "#del model  # deletes the existing model\n",
    "    \n",
    "#returns a compiled model\n",
    "#identical to the previous one\n",
    "#model = load_model('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Loading Models\n",
    "model = load_model('models/trained_model_Sikai_20231018_1.keras') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look of the model layers summarry\n",
    "model.model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
